1.In this block, I used the `nibabel` library to load a NIfTI brain scan and examine its structure. I began by importing the library and then provided the path to the `.nii` file I wanted to work with. Using `nb.load()`, I loaded the file and extracted the actual imaging data as a NumPy array with `get_fdata()`. Once I had the data, I printed out its shape to understand the dimensions of the 3D volume, which tells me how many voxels there are along each axis. I also checked the data type to see how the voxel values are stored, and confirmed the number of dimensions to ensure it’s a standard 3D scan. Lastly, I calculated the total number of voxels by multiplying the dimensions together, which gives me a sense of the image's overall size and complexity.

2. I used file.affine to get the affine matrix of the NIfTI file, which tells me how the voxel data is positioned in real-world space. This 4×4 matrix contains information about the orientation, spacing, and location of the image. By printing it, I can see how the scan is mapped in physical coordinates, which is useful if I need to align or compare it with other scans.

4. I’m using Matplotlib to visualize a single slice from the 3D image. I take the middle slice along the first axis using integer division, then extract that 2D slice from the NumPy array. Finally, I display it using imshow() with a grayscale colormap ("bone") to get a clear look at the anatomical details in that section.

5. In this script, I’m reading multiple DICOM series from a set of folders to inspect their metadata. I loop through three folder paths where each one represents a different DICOM series. For each folder, I list the files and pick the first one, assuming it’s a valid DICOM file. I use pydicom to read that file and extract key patient and image information — like the patient’s name, ID, study date, scan position, orientation, modality, slice details, resolution, and pixel format. I use getattr() with default values to avoid errors if any fields are missing. This gives me a quick overview of the scan's properties without having to open or view the images directly, which is helpful for understanding what's inside a series before processing it further.  It was difficult to acquire the data I then asked one of my friends for his source. I used a source earlier but it didn’t have complete metadata and I also had to convert it form NIfTI to DICOM.

6. I wrote two simple helper functions to work with a collection of DICOM slices. The first function, arrange_slices_by_location, sorts the slices based on their physical position in space using the SliceLocation attribute — this helps me line up the slices in the correct order. The second function, stack_slices_into_volume, takes the sorted 2D slices and stacks them one by one into a 3D NumPy array, effectively rebuilding the whole volume from the individual images. This way, I can easily convert scattered slices into a structured 3D dataset ready for analysis or visualization.

7. In continuation to the above step, I start by gathering all the DICOM files from each of the three series folders and reading them into separate lists using pydicom. For each series, I list the files in the folder, read each DICOM file, and store the loaded images. Then, I organize the slices in each series by their physical position using my helper function arrange_slices_by_location to make sure the slices are in the correct order. After sorting, I convert each series of 2D slices into a 3D NumPy array with stack_slices_into_volume, stacking the slices into a volumetric dataset.I also check to see whether everything is running smoothly.

8. Finally, I print every view and I have used a bone colourmap as was used in the resources shared. 


